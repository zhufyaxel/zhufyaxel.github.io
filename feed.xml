<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://zhufyaxel.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://zhufyaxel.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-17T01:55:39+00:00</updated><id>https://zhufyaxel.github.io/feed.xml</id><title type="html">Fengyuan Zhu’s Research Space</title><subtitle>This is the website to show Fengyuan&apos;s research process. </subtitle><entry xml:lang="zh"><title type="html">多语言演示</title><link href="https://zhufyaxel.github.io/blog/2025/multilingual-demo-zh/" rel="alternate" type="text/html" title="多语言演示"/><published>2025-04-16T00:00:00+00:00</published><updated>2025-04-16T00:00:00+00:00</updated><id>https://zhufyaxel.github.io/blog/2025/multilingual-demo-zh</id><content type="html" xml:base="https://zhufyaxel.github.io/blog/2025/multilingual-demo-zh/"><![CDATA[<h1 id="多语言演示">多语言演示</h1> <p>这是多语言功能的演示。这篇文章是中文的，但您可以使用上方的语言切换器切换到英文。</p> <h2 id="工作原理">工作原理</h2> <ol> <li>每篇文章在前置元数据中都有一个 <code class="language-plaintext highlighter-rouge">lang</code> 参数，用于指定文章的语言。</li> <li><code class="language-plaintext highlighter-rouge">other_languages</code> 参数包含语言代码到同一篇文章其他语言版本URL的映射。</li> <li>语言切换器组件显示指向文章其他语言版本的链接。</li> </ol> <h2 id="创建多语言内容">创建多语言内容</h2> <p>要创建多语言内容，您需要：</p> <ol> <li>为内容的每种语言版本创建单独的文件。</li> <li>在每个文件的前置元数据中添加 <code class="language-plaintext highlighter-rouge">lang</code> 参数。</li> <li>在每个文件的前置元数据中添加 <code class="language-plaintext highlighter-rouge">other_languages</code> 参数，将语言代码映射到URL。</li> </ol> <p>例如，这篇文章的前置元数据如下：</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">---</span>
<span class="na">layout</span><span class="pi">:</span> <span class="s">post</span>
<span class="na">title</span><span class="pi">:</span> <span class="s">多语言演示</span>
<span class="na">date</span><span class="pi">:</span> <span class="s">2025-04-16</span>
<span class="na">description</span><span class="pi">:</span> <span class="s">多语言功能的演示</span>
<span class="na">tags</span><span class="pi">:</span> <span class="s">demo multilingual</span>
<span class="na">categories</span><span class="pi">:</span> <span class="s">sample-posts</span>
<span class="na">lang</span><span class="pi">:</span> <span class="s">zh</span>
<span class="na">other_languages</span><span class="pi">:</span>
  <span class="na">en</span><span class="pi">:</span> <span class="s">/blog/2025/multilingual-demo/</span>
<span class="nn">---</span>
</code></pre></div></div> <p>而英文版本的前置元数据为：</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">---</span>
<span class="na">layout</span><span class="pi">:</span> <span class="s">post</span>
<span class="na">title</span><span class="pi">:</span> <span class="s">Multilingual Demo</span>
<span class="na">date</span><span class="pi">:</span> <span class="s">2025-04-16</span>
<span class="na">description</span><span class="pi">:</span> <span class="s">A demonstration of the multilingual feature</span>
<span class="na">tags</span><span class="pi">:</span> <span class="s">demo multilingual</span>
<span class="na">categories</span><span class="pi">:</span> <span class="s">sample-posts</span>
<span class="na">lang</span><span class="pi">:</span> <span class="s">en</span>
<span class="na">other_languages</span><span class="pi">:</span>
  <span class="na">zh</span><span class="pi">:</span> <span class="s">/blog/2025/multilingual-demo-zh/</span>
<span class="nn">---</span>
</code></pre></div></div> <h2 id="优势">优势</h2> <ul> <li>用户可以轻松地在同一内容的不同语言版本之间切换。</li> <li>搜索引擎可以正确索引不同语言的内容。</li> <li>您可以为每种语言版本维护单独的URL。</li> </ul>]]></content><author><name></name></author><category term="sample-posts"/><category term="demo"/><category term="multilingual"/><summary type="html"><![CDATA[多语言功能的演示]]></summary></entry><entry xml:lang="en"><title type="html">Multilingual Demo</title><link href="https://zhufyaxel.github.io/blog/2025/multilingual-demo/" rel="alternate" type="text/html" title="Multilingual Demo"/><published>2025-04-16T00:00:00+00:00</published><updated>2025-04-16T00:00:00+00:00</updated><id>https://zhufyaxel.github.io/blog/2025/multilingual-demo</id><content type="html" xml:base="https://zhufyaxel.github.io/blog/2025/multilingual-demo/"><![CDATA[<h1 id="multilingual-demo">Multilingual Demo</h1> <p>This is a demonstration of the multilingual feature. This post is in English, but you can switch to Chinese using the language switcher above.</p> <h2 id="how-it-works">How it works</h2> <ol> <li>Each post has a <code class="language-plaintext highlighter-rouge">lang</code> parameter in the front matter that specifies the language of the post.</li> <li>The <code class="language-plaintext highlighter-rouge">other_languages</code> parameter contains a mapping of language codes to URLs of the same post in other languages.</li> <li>The language switcher component displays links to the other language versions of the post.</li> </ol> <h2 id="creating-multilingual-content">Creating multilingual content</h2> <p>To create multilingual content, you need to:</p> <ol> <li>Create separate files for each language version of your content.</li> <li>Add the <code class="language-plaintext highlighter-rouge">lang</code> parameter to the front matter of each file.</li> <li>Add the <code class="language-plaintext highlighter-rouge">other_languages</code> parameter to the front matter of each file, mapping language codes to URLs.</li> </ol> <p>For example, this post has the following front matter:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">---</span>
<span class="na">layout</span><span class="pi">:</span> <span class="s">post</span>
<span class="na">title</span><span class="pi">:</span> <span class="s">Multilingual Demo</span>
<span class="na">date</span><span class="pi">:</span> <span class="s">2025-04-16</span>
<span class="na">description</span><span class="pi">:</span> <span class="s">A demonstration of the multilingual feature</span>
<span class="na">tags</span><span class="pi">:</span> <span class="s">demo multilingual</span>
<span class="na">categories</span><span class="pi">:</span> <span class="s">sample-posts</span>
<span class="na">lang</span><span class="pi">:</span> <span class="s">en</span>
<span class="na">other_languages</span><span class="pi">:</span>
  <span class="na">zh</span><span class="pi">:</span> <span class="s">/blog/2025/multilingual-demo-zh/</span>
<span class="nn">---</span>
</code></pre></div></div> <p>And the Chinese version has:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">---</span>
<span class="na">layout</span><span class="pi">:</span> <span class="s">post</span>
<span class="na">title</span><span class="pi">:</span> <span class="s">多语言演示</span>
<span class="na">date</span><span class="pi">:</span> <span class="s">2025-04-16</span>
<span class="na">description</span><span class="pi">:</span> <span class="s">多语言功能的演示</span>
<span class="na">tags</span><span class="pi">:</span> <span class="s">demo multilingual</span>
<span class="na">categories</span><span class="pi">:</span> <span class="s">sample-posts</span>
<span class="na">lang</span><span class="pi">:</span> <span class="s">zh</span>
<span class="na">other_languages</span><span class="pi">:</span>
  <span class="na">en</span><span class="pi">:</span> <span class="s">/blog/2025/multilingual-demo/</span>
<span class="nn">---</span>
</code></pre></div></div> <h2 id="benefits">Benefits</h2> <ul> <li>Users can easily switch between languages for the same content.</li> <li>Search engines can properly index content in different languages.</li> <li>You can maintain separate URLs for each language version.</li> </ul>]]></content><author><name></name></author><category term="sample-posts"/><category term="demo"/><category term="multilingual"/><summary type="html"><![CDATA[A demonstration of the multilingual feature]]></summary></entry><entry xml:lang="zh"><title type="html">使用视频预览增强论文展示</title><link href="https://zhufyaxel.github.io/blog/2025/video-preview-demo-zh/" rel="alternate" type="text/html" title="使用视频预览增强论文展示"/><published>2025-04-16T00:00:00+00:00</published><updated>2025-04-16T00:00:00+00:00</updated><id>https://zhufyaxel.github.io/blog/2025/video-preview-demo-zh</id><content type="html" xml:base="https://zhufyaxel.github.io/blog/2025/video-preview-demo-zh/"><![CDATA[<h1 id="使用视频预览增强论文展示">使用视频预览增强论文展示</h1> <p>这个学术网站模板的最强大功能之一是能够为精选论文添加视频预览。这为您的研究提供了一种引人入胜且动态的展示方式。</p> <h2 id="视频预览的工作原理">视频预览的工作原理</h2> <p>当访问者浏览您的精选出版物时，他们会看到自动播放的视频预览，这些预览能快速直观地展示您的论文内容。这对于包含视觉元素、用户界面或交互系统的研究特别有效。</p> <p>以下是我的一些带有视频预览的精选论文：</p> <div class="publications"> <ol class="bibliography"><li><div class="row publication-entry"> <div class="col-sm-4 col-md-4 abbr"> <figure> <div class="video-container" data-zoomable="" data-video-path="/assets/video/publication_preview/BeyondThePhone.mp4"> <video class="preview z-depth-1 rounded" width="100%" height="auto" autoplay="" muted="" loop="" playsinline="" preload="auto" loading="eager" poster="/assets/video/publication_preview/BeyondThePhone.jpg" onerror="this.style.display='none'; document.getElementById('fallback-assets-video-publication-preview-beyondthephone-mp4').style.display='block';"> <source src="/assets/video/publication_preview/BeyondThePhone.mp4" type="video/mp4"/> <source src="/assets/video/publication_preview/BeyondThePhone.webm" type="video/webm"/> Your browser does not support the video tag. </video> <div class="video-play-overlay"> <div class="play-button-large"></div> </div> <div id="fallback-assets-video-publication-preview-beyondthephone-mp4" class="video-fallback" style="display:none;" data-video-path="/assets/video/publication_preview/BeyondThePhone.mp4"> <img src="/assets/video/publication_preview/BeyondThePhone.jpg" alt="Video preview image" class="preview z-depth-1 rounded"/> <div class="play-button-large"></div> </div> </div> </figure> <style>.video-container{position:relative;width:100%;cursor:pointer;overflow:hidden;border-radius:4px;transition:transform .3s ease,box-shadow .3s ease}.video-container:hover{transform:scale(1.01);box-shadow:0 4px 8px rgba(0,0,0,0.1)}.video-container video{display:block;max-width:100%}.video-play-overlay{position:absolute;top:0;left:0;width:100%;height:100%;background-color:rgba(0,0,0,0.1);opacity:0;transition:opacity .3s ease;display:flex;align-items:center;justify-content:center}.video-container:hover .video-play-overlay{opacity:1}.video-fallback{position:relative;width:100%;cursor:pointer}.video-fallback img{width:100%;height:auto;display:block;border-radius:4px}.play-button-large{width:80px;height:80px;background-color:rgba(0,0,0,0.6);border-radius:50%;display:flex;align-items:center;justify-content:center;transition:background-color .3s ease,transform .3s ease}.play-button-large:before{content:'';display:block;width:0;height:0;border-top:15px solid transparent;border-bottom:15px solid transparent;border-left:25px solid white;margin-left:5px}.video-container:hover .play-button-large,.video-fallback:hover .play-button-large{background-color:rgba(0,0,0,0.8);transform:scale(1.1)}</style> </div> <div id="BeyondThePhone" class="col-sm-8 col-md-8 publication-content"> <div class="title"> Beyond the Phone: Exploring Phone-XR Integration through Multi-View Transitions for Real-World Applications </div> <div class="author"> <em>Fengyuan Zhu</em>,&nbsp;Xun Qian ,&nbsp;Daniel Kalmar ,&nbsp;Mahdi Tayarani ,&nbsp;Eric J. Gonzalez ,&nbsp;Mar Gonzalez-Franco ,&nbsp;David Kim ,&nbsp;and&nbsp;Ruofei Du </div> <div class="periodical"> <em>In 2025 IEEE Conference Virtual Reality and 3D User Interfaces (VR)</em> , Saint Malo, France, 2025 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/IEEEVR25_Beyond_the_Phone.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/vSjj8C-d4qo?si=TEG0mgeMj86UVWoP" class="btn btn-sm z-depth-0" role="button">Video</a> </div> <div class="abstract hidden"> <p>Despite the growing prevalence of Extended Reality (XR) headsets, their integration with mobile phones remains limited. Existing approaches primarily replicate the phone’s interface in XR or use the phone solely as a 6DOF controller. This paper introduces a novel framework for seamless transitions among mirrored, magnified, and augmented views, dynamically adapts the interface with the content and state of mobile applications. To achieve this, we establish a design space through literature reviews and expert workshops, outline user journeys with common real-world applications, and develop a prototype system that automatically analyzes UI layouts to provide enhanced controls and spatial augmentation. We validate our prototype system with a user study to assess its adaptability to a broad spectrum of applications at runtime, reported its strengths and weaknesses, and suggest directions to advance the future adaption in Phone-XR integration.</p> </div> </div> </div> </li> <li><div class="row publication-entry"> <div class="col-sm-4 col-md-4 abbr"> <figure> <div class="video-container" data-zoomable="" data-video-path="/assets/video/publication_preview/bishare.mp4"> <video class="preview z-depth-1 rounded" width="100%" height="auto" autoplay="" muted="" loop="" playsinline="" preload="auto" loading="eager" poster="/assets/video/publication_preview/bishare.jpg" onerror="this.style.display='none'; document.getElementById('fallback-assets-video-publication-preview-bishare-mp4').style.display='block';"> <source src="/assets/video/publication_preview/bishare.mp4" type="video/mp4"/> <source src="/assets/video/publication_preview/bishare.webm" type="video/webm"/> Your browser does not support the video tag. </video> <div class="video-play-overlay"> <div class="play-button-large"></div> </div> <div id="fallback-assets-video-publication-preview-bishare-mp4" class="video-fallback" style="display:none;" data-video-path="/assets/video/publication_preview/bishare.mp4"> <img src="/assets/video/publication_preview/bishare.jpg" alt="Video preview image" class="preview z-depth-1 rounded"/> <div class="play-button-large"></div> </div> </div> </figure> <style>.video-container{position:relative;width:100%;cursor:pointer;overflow:hidden;border-radius:4px;transition:transform .3s ease,box-shadow .3s ease}.video-container:hover{transform:scale(1.01);box-shadow:0 4px 8px rgba(0,0,0,0.1)}.video-container video{display:block;max-width:100%}.video-play-overlay{position:absolute;top:0;left:0;width:100%;height:100%;background-color:rgba(0,0,0,0.1);opacity:0;transition:opacity .3s ease;display:flex;align-items:center;justify-content:center}.video-container:hover .video-play-overlay{opacity:1}.video-fallback{position:relative;width:100%;cursor:pointer}.video-fallback img{width:100%;height:auto;display:block;border-radius:4px}.play-button-large{width:80px;height:80px;background-color:rgba(0,0,0,0.6);border-radius:50%;display:flex;align-items:center;justify-content:center;transition:background-color .3s ease,transform .3s ease}.play-button-large:before{content:'';display:block;width:0;height:0;border-top:15px solid transparent;border-bottom:15px solid transparent;border-left:25px solid white;margin-left:5px}.video-container:hover .play-button-large,.video-fallback:hover .play-button-large{background-color:rgba(0,0,0,0.8);transform:scale(1.1)}</style> </div> <div id="BISHARE" class="col-sm-8 col-md-8 publication-content"> <div class="title"> BISHARE: Exploring Bidirectional Interactions Between Smartphones and Head-Mounted Augmented Reality <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1145/3313831.3376233" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> <div class="author"> <em>Fengyuan Zhu</em>,&nbsp;and&nbsp;Tovi Grossman </div> <div class="periodical"> <em>In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</em> , Honolulu, HI, USA, 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/BISHARE.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.youtube.com/watch?v=hkL4cKUleNw" class="btn btn-sm z-depth-0" role="button">Video</a> </div> <div class="abstract hidden"> <p>In pursuit of a future where HMD devices can be used in tandem with smartphones and other smart devices, we present BISHARE, a design space of cross-device interactions between smartphones and ARHMDs. Our design space is unique in that it is bidirectional in nature, as it examines how both the HMD can be used to enhance smartphone tasks, and how the smartphone can be used to enhance HMD tasks. We then present an interactive prototype that enables cross-device interactions across the proposed design space. A 12-participant user study demonstrates the promise of the design space and provides insights, observations, and guidance for the future.</p> </div> </div> </div> </li> <li><div class="row publication-entry"> <div class="col-sm-4 col-md-4 abbr"> <figure> <div class="video-container" data-zoomable="" data-video-path="/assets/video/publication_preview/PhoneInVR.mp4"> <video class="preview z-depth-1 rounded" width="100%" height="auto" autoplay="" muted="" loop="" playsinline="" preload="auto" loading="eager" poster="/assets/video/publication_preview/PhoneInVR.jpg" onerror="this.style.display='none'; document.getElementById('fallback-assets-video-publication-preview-phoneinvr-mp4').style.display='block';"> <source src="/assets/video/publication_preview/PhoneInVR.mp4" type="video/mp4"/> <source src="/assets/video/publication_preview/PhoneInVR.webm" type="video/webm"/> Your browser does not support the video tag. </video> <div class="video-play-overlay"> <div class="play-button-large"></div> </div> <div id="fallback-assets-video-publication-preview-phoneinvr-mp4" class="video-fallback" style="display:none;" data-video-path="/assets/video/publication_preview/PhoneInVR.mp4"> <img src="/assets/video/publication_preview/PhoneInVR.jpg" alt="Video preview image" class="preview z-depth-1 rounded"/> <div class="play-button-large"></div> </div> </div> </figure> <style>.video-container{position:relative;width:100%;cursor:pointer;overflow:hidden;border-radius:4px;transition:transform .3s ease,box-shadow .3s ease}.video-container:hover{transform:scale(1.01);box-shadow:0 4px 8px rgba(0,0,0,0.1)}.video-container video{display:block;max-width:100%}.video-play-overlay{position:absolute;top:0;left:0;width:100%;height:100%;background-color:rgba(0,0,0,0.1);opacity:0;transition:opacity .3s ease;display:flex;align-items:center;justify-content:center}.video-container:hover .video-play-overlay{opacity:1}.video-fallback{position:relative;width:100%;cursor:pointer}.video-fallback img{width:100%;height:auto;display:block;border-radius:4px}.play-button-large{width:80px;height:80px;background-color:rgba(0,0,0,0.6);border-radius:50%;display:flex;align-items:center;justify-content:center;transition:background-color .3s ease,transform .3s ease}.play-button-large:before{content:'';display:block;width:0;height:0;border-top:15px solid transparent;border-bottom:15px solid transparent;border-left:25px solid white;margin-left:5px}.video-container:hover .play-button-large,.video-fallback:hover .play-button-large{background-color:rgba(0,0,0,0.8);transform:scale(1.1)}</style> </div> <div id="PhoneInVR" class="col-sm-8 col-md-8 publication-content"> <div class="title"> PhoneInVR: An Evaluation of Spatial Anchoring and Interaction Techniques for Smartphone Usage in Virtual Reality </div> <div class="author"> <em>Fengyuan Zhu</em>,&nbsp;Mauricio Sousa ,&nbsp;Ludwig Sidenmark ,&nbsp;and&nbsp;Tovi Grossman </div> <div class="periodical"> <em>In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems</em> , Honolulu, HI, USA, 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/PhoneInVR.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.youtube.com/watch?v=pQN98TbhAKM" class="btn btn-sm z-depth-0" role="button">Video</a> </div> <div class="abstract hidden"> <p>When users wear a virtual reality (VR) headset, they lose access to their smartphone and accompanying apps. Past work has proposed smartphones as enhanced VR controllers, but little work has explored using existing smartphone apps and performing traditional smartphone interactions while in VR. In this paper, we consider three potential spatial anchorings for rendering smartphones in VR: On top of a tracked physical smartphone which the user holds (Phone-locked), on top of the users empty hand, as if holding a virtual smartphone (Hand-locked), or in a static position in front of the user (World-locked). We conducted a comparative study of target acquisition, swiping, and scrolling tasks across these anchorings using direct Touch or above-the-surface Pinch. Our findings indicate that physically holding a smartphone with Touch improves accuracy and speed for all tasks, and Pinch performed better with virtual smartphones. These findings provide a valuable foundation to enable smartphones in VR. </p> </div> </div> </div> </li> <li><div class="row publication-entry"> <div class="col-sm-4 col-md-4 abbr"> <figure> <div class="video-container" data-zoomable="" data-video-path="/assets/video/publication_preview/PinchLens.mp4"> <video class="preview z-depth-1 rounded" width="100%" height="auto" autoplay="" muted="" loop="" playsinline="" preload="auto" loading="eager" poster="/assets/video/publication_preview/PinchLens.jpg" onerror="this.style.display='none'; document.getElementById('fallback-assets-video-publication-preview-pinchlens-mp4').style.display='block';"> <source src="/assets/video/publication_preview/PinchLens.mp4" type="video/mp4"/> <source src="/assets/video/publication_preview/PinchLens.webm" type="video/webm"/> Your browser does not support the video tag. </video> <div class="video-play-overlay"> <div class="play-button-large"></div> </div> <div id="fallback-assets-video-publication-preview-pinchlens-mp4" class="video-fallback" style="display:none;" data-video-path="/assets/video/publication_preview/PinchLens.mp4"> <img src="/assets/video/publication_preview/PinchLens.jpg" alt="Video preview image" class="preview z-depth-1 rounded"/> <div class="play-button-large"></div> </div> </div> </figure> <style>.video-container{position:relative;width:100%;cursor:pointer;overflow:hidden;border-radius:4px;transition:transform .3s ease,box-shadow .3s ease}.video-container:hover{transform:scale(1.01);box-shadow:0 4px 8px rgba(0,0,0,0.1)}.video-container video{display:block;max-width:100%}.video-play-overlay{position:absolute;top:0;left:0;width:100%;height:100%;background-color:rgba(0,0,0,0.1);opacity:0;transition:opacity .3s ease;display:flex;align-items:center;justify-content:center}.video-container:hover .video-play-overlay{opacity:1}.video-fallback{position:relative;width:100%;cursor:pointer}.video-fallback img{width:100%;height:auto;display:block;border-radius:4px}.play-button-large{width:80px;height:80px;background-color:rgba(0,0,0,0.6);border-radius:50%;display:flex;align-items:center;justify-content:center;transition:background-color .3s ease,transform .3s ease}.play-button-large:before{content:'';display:block;width:0;height:0;border-top:15px solid transparent;border-bottom:15px solid transparent;border-left:25px solid white;margin-left:5px}.video-container:hover .play-button-large,.video-fallback:hover .play-button-large{background-color:rgba(0,0,0,0.8);transform:scale(1.1)}</style> </div> <div id="PinchLens" class="col-sm-8 col-md-8 publication-content"> <div class="title"> PinchLens: Applying Spatial Magnification and Adaptive Control-Display Gain for Precise Selection in Virtual Reality </div> <div class="author"> <em>Fengyuan Zhu</em>,&nbsp;Ludwig Sidenmark ,&nbsp;Mauricio Sousa ,&nbsp;and&nbsp;Tovi Grossman </div> <div class="periodical"> <em>In 2023 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</em> , Sydney, New South Wales, Australia, 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/PinchLens.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/MAlkiWVsMeQ?si=zPMXPQNwDKb0Yoc5" class="btn btn-sm z-depth-0" role="button">Video</a> </div> <div class="abstract hidden"> <p>We present PinchLens, a new free-hand target selection technique for acquiring small and dense targets in Virtual Reality. Traditional pinch-based selection does not allow people to precisely manipulate small and dense objects effectively due to tracking and perceptual inaccuracies. Our approach combines spatial magnification, an adaptive control-display gain, and visual feedback to improve selection accuracy. When a user starts the pinching selection process, a magnifying bubble expands the scale of nearby targets, an adaptive control-to-display ratio is applied to the user‘s hand for precision, and a cursor is displayed at the estimated pinch point for enhanced visual feedback. We performed a user study to compare our technique to traditional pinch selection and several variations to isolate the impact of each of the technique’s features. The results showed that PinchLens significantly outperformed traditional pinch selection, reducing error rates from 18.9% to 1.9%. Furthermore, we found that magnification was the dominant feature to produce this improvement, while the adaptive control-display gain and visual cursor of pinch were also helpful in several conditions.</p> </div> </div> </div> </li></ol> </div> <h2 id="如何为论文添加视频预览">如何为论文添加视频预览</h2> <p>为您的出版物添加视频预览非常简单。在您的BibTeX条目（通常在<code class="language-plaintext highlighter-rouge">_bibliography/papers.bib</code>中）中，您需要添加两个关键元素：</p> <ol> <li>通过添加<code class="language-plaintext highlighter-rouge">selected={true}</code>将论文标记为精选</li> <li>通过包含<code class="language-plaintext highlighter-rouge">preview={YourPaperName.mp4}</code>添加视频预览</li> </ol> <p>以下是带有视频预览的BibTeX条目示例：</p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@INPROCEEDINGS</span><span class="p">{</span><span class="nl">PaperKey</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Author, A. and Researcher, B.}</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Your Amazing Research Paper}</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{2025 Conference Proceedings}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2025}</span><span class="p">,</span>
  <span class="na">pages</span><span class="p">=</span><span class="s">{1-10}</span><span class="p">,</span>
  <span class="na">abstract</span><span class="p">=</span><span class="s">{Your paper abstract goes here...}</span><span class="p">,</span>
  <span class="na">selected</span><span class="p">=</span><span class="s">{true}</span><span class="p">,</span>
  <span class="na">preview</span><span class="p">=</span><span class="s">{YourPaperName.mp4}</span><span class="p">,</span>
  <span class="na">pdf</span><span class="p">=</span><span class="s">{YourPaper.pdf}</span><span class="p">,</span>
  <span class="na">video</span><span class="p">=</span><span class="s">{https://youtu.be/your-full-video}</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="视频要求和技巧">视频要求和技巧</h2> <p>为了获得最佳的视频预览效果：</p> <ol> <li><strong>格式</strong>：创建MP4文件以获得最佳兼容性</li> <li><strong>时长</strong>：保持视频简短（5-15秒）以快速传达关键视觉方面</li> <li><strong>大小</strong>：优化文件大小以确保快速加载</li> <li><strong>内容</strong>：专注于您研究中最具视觉吸引力的方面</li> <li><strong>无音频</strong>：视频以静音方式播放，因此视觉内容是关键</li> <li><strong>备用图像</strong>：系统会自动使用同名的JPG作为备用选项</li> </ol> <h2 id="文件组织">文件组织</h2> <p>将您的视频预览文件放在<code class="language-plaintext highlighter-rouge">/assets/video/publication_preview/</code>目录中。系统会自动在那里查找它们。</p> <h2 id="视频预览的好处">视频预览的好处</h2> <p>为您的精选论文添加视频预览提供了几个优势：</p> <ul> <li><strong>增加参与度</strong>：访问者更有可能注意到并探索具有动态内容的论文</li> <li><strong>更好的理解</strong>：复杂概念可以通过视觉方式快速传达</li> <li><strong>专业外观</strong>：为您的研究创建现代、交互式的展示</li> <li><strong>差异化</strong>：从传统的静态出版物列表中脱颖而出</li> </ul> <p>通过为您的关键出版物实现视频预览，您可以创建一个更具吸引力和信息量的学术网站，有效地展示您的研究贡献。</p>]]></content><author><name></name></author><category term="tutorials"/><category term="demo"/><category term="video"/><category term="publications"/><summary type="html"><![CDATA[如何为精选论文添加吸引人的视频预览]]></summary></entry><entry xml:lang="en"><title type="html">Enhancing Publications with Video Previews</title><link href="https://zhufyaxel.github.io/blog/2025/video-preview-demo/" rel="alternate" type="text/html" title="Enhancing Publications with Video Previews"/><published>2025-04-16T00:00:00+00:00</published><updated>2025-04-16T00:00:00+00:00</updated><id>https://zhufyaxel.github.io/blog/2025/video-preview-demo</id><content type="html" xml:base="https://zhufyaxel.github.io/blog/2025/video-preview-demo/"><![CDATA[<h1 id="enhancing-publications-with-video-previews">Enhancing Publications with Video Previews</h1> <p>In this for, I have added the feature of rendering video previews to your selected papers. This creates an engaging and dynamic way to showcase your research at a glance.</p> <h2 id="how-video-previews-work">How Video Previews Work</h2> <p>When a visitor browses your selected publications, they’ll see an autoplay video preview that gives a quick visual overview of your paper. This is particularly effective for research that involves visual elements, user interfaces, or interactive systems.</p> <p>Here’s how some of my selected papers appear with video previews:</p> <div class="publications"> <ol class="bibliography"><li><div class="row publication-entry"> <div class="col-sm-4 col-md-4 abbr"> <figure> <div class="video-container" data-zoomable="" data-video-path="/assets/video/publication_preview/BeyondThePhone.mp4"> <video class="preview z-depth-1 rounded" width="100%" height="auto" autoplay="" muted="" loop="" playsinline="" preload="auto" loading="eager" poster="/assets/video/publication_preview/BeyondThePhone.jpg" onerror="this.style.display='none'; document.getElementById('fallback-assets-video-publication-preview-beyondthephone-mp4').style.display='block';"> <source src="/assets/video/publication_preview/BeyondThePhone.mp4" type="video/mp4"/> <source src="/assets/video/publication_preview/BeyondThePhone.webm" type="video/webm"/> Your browser does not support the video tag. </video> <div class="video-play-overlay"> <div class="play-button-large"></div> </div> <div id="fallback-assets-video-publication-preview-beyondthephone-mp4" class="video-fallback" style="display:none;" data-video-path="/assets/video/publication_preview/BeyondThePhone.mp4"> <img src="/assets/video/publication_preview/BeyondThePhone.jpg" alt="Video preview image" class="preview z-depth-1 rounded"/> <div class="play-button-large"></div> </div> </div> </figure> <style>.video-container{position:relative;width:100%;cursor:pointer;overflow:hidden;border-radius:4px;transition:transform .3s ease,box-shadow .3s ease}.video-container:hover{transform:scale(1.01);box-shadow:0 4px 8px rgba(0,0,0,0.1)}.video-container video{display:block;max-width:100%}.video-play-overlay{position:absolute;top:0;left:0;width:100%;height:100%;background-color:rgba(0,0,0,0.1);opacity:0;transition:opacity .3s ease;display:flex;align-items:center;justify-content:center}.video-container:hover .video-play-overlay{opacity:1}.video-fallback{position:relative;width:100%;cursor:pointer}.video-fallback img{width:100%;height:auto;display:block;border-radius:4px}.play-button-large{width:80px;height:80px;background-color:rgba(0,0,0,0.6);border-radius:50%;display:flex;align-items:center;justify-content:center;transition:background-color .3s ease,transform .3s ease}.play-button-large:before{content:'';display:block;width:0;height:0;border-top:15px solid transparent;border-bottom:15px solid transparent;border-left:25px solid white;margin-left:5px}.video-container:hover .play-button-large,.video-fallback:hover .play-button-large{background-color:rgba(0,0,0,0.8);transform:scale(1.1)}</style> </div> <div id="BeyondThePhone" class="col-sm-8 col-md-8 publication-content"> <div class="title"> Beyond the Phone: Exploring Phone-XR Integration through Multi-View Transitions for Real-World Applications </div> <div class="author"> <em>Fengyuan Zhu</em>,&nbsp;Xun Qian ,&nbsp;Daniel Kalmar ,&nbsp;Mahdi Tayarani ,&nbsp;Eric J. Gonzalez ,&nbsp;Mar Gonzalez-Franco ,&nbsp;David Kim ,&nbsp;and&nbsp;Ruofei Du </div> <div class="periodical"> <em>In 2025 IEEE Conference Virtual Reality and 3D User Interfaces (VR)</em> , Saint Malo, France, 2025 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/IEEEVR25_Beyond_the_Phone.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/vSjj8C-d4qo?si=TEG0mgeMj86UVWoP" class="btn btn-sm z-depth-0" role="button">Video</a> </div> <div class="abstract hidden"> <p>Despite the growing prevalence of Extended Reality (XR) headsets, their integration with mobile phones remains limited. Existing approaches primarily replicate the phone’s interface in XR or use the phone solely as a 6DOF controller. This paper introduces a novel framework for seamless transitions among mirrored, magnified, and augmented views, dynamically adapts the interface with the content and state of mobile applications. To achieve this, we establish a design space through literature reviews and expert workshops, outline user journeys with common real-world applications, and develop a prototype system that automatically analyzes UI layouts to provide enhanced controls and spatial augmentation. We validate our prototype system with a user study to assess its adaptability to a broad spectrum of applications at runtime, reported its strengths and weaknesses, and suggest directions to advance the future adaption in Phone-XR integration.</p> </div> </div> </div> </li> <li><div class="row publication-entry"> <div class="col-sm-4 col-md-4 abbr"> <figure> <div class="video-container" data-zoomable="" data-video-path="/assets/video/publication_preview/bishare.mp4"> <video class="preview z-depth-1 rounded" width="100%" height="auto" autoplay="" muted="" loop="" playsinline="" preload="auto" loading="eager" poster="/assets/video/publication_preview/bishare.jpg" onerror="this.style.display='none'; document.getElementById('fallback-assets-video-publication-preview-bishare-mp4').style.display='block';"> <source src="/assets/video/publication_preview/bishare.mp4" type="video/mp4"/> <source src="/assets/video/publication_preview/bishare.webm" type="video/webm"/> Your browser does not support the video tag. </video> <div class="video-play-overlay"> <div class="play-button-large"></div> </div> <div id="fallback-assets-video-publication-preview-bishare-mp4" class="video-fallback" style="display:none;" data-video-path="/assets/video/publication_preview/bishare.mp4"> <img src="/assets/video/publication_preview/bishare.jpg" alt="Video preview image" class="preview z-depth-1 rounded"/> <div class="play-button-large"></div> </div> </div> </figure> <style>.video-container{position:relative;width:100%;cursor:pointer;overflow:hidden;border-radius:4px;transition:transform .3s ease,box-shadow .3s ease}.video-container:hover{transform:scale(1.01);box-shadow:0 4px 8px rgba(0,0,0,0.1)}.video-container video{display:block;max-width:100%}.video-play-overlay{position:absolute;top:0;left:0;width:100%;height:100%;background-color:rgba(0,0,0,0.1);opacity:0;transition:opacity .3s ease;display:flex;align-items:center;justify-content:center}.video-container:hover .video-play-overlay{opacity:1}.video-fallback{position:relative;width:100%;cursor:pointer}.video-fallback img{width:100%;height:auto;display:block;border-radius:4px}.play-button-large{width:80px;height:80px;background-color:rgba(0,0,0,0.6);border-radius:50%;display:flex;align-items:center;justify-content:center;transition:background-color .3s ease,transform .3s ease}.play-button-large:before{content:'';display:block;width:0;height:0;border-top:15px solid transparent;border-bottom:15px solid transparent;border-left:25px solid white;margin-left:5px}.video-container:hover .play-button-large,.video-fallback:hover .play-button-large{background-color:rgba(0,0,0,0.8);transform:scale(1.1)}</style> </div> <div id="BISHARE" class="col-sm-8 col-md-8 publication-content"> <div class="title"> BISHARE: Exploring Bidirectional Interactions Between Smartphones and Head-Mounted Augmented Reality <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1145/3313831.3376233" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> <div class="author"> <em>Fengyuan Zhu</em>,&nbsp;and&nbsp;Tovi Grossman </div> <div class="periodical"> <em>In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</em> , Honolulu, HI, USA, 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/BISHARE.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.youtube.com/watch?v=hkL4cKUleNw" class="btn btn-sm z-depth-0" role="button">Video</a> </div> <div class="abstract hidden"> <p>In pursuit of a future where HMD devices can be used in tandem with smartphones and other smart devices, we present BISHARE, a design space of cross-device interactions between smartphones and ARHMDs. Our design space is unique in that it is bidirectional in nature, as it examines how both the HMD can be used to enhance smartphone tasks, and how the smartphone can be used to enhance HMD tasks. We then present an interactive prototype that enables cross-device interactions across the proposed design space. A 12-participant user study demonstrates the promise of the design space and provides insights, observations, and guidance for the future.</p> </div> </div> </div> </li> <li><div class="row publication-entry"> <div class="col-sm-4 col-md-4 abbr"> <figure> <div class="video-container" data-zoomable="" data-video-path="/assets/video/publication_preview/PhoneInVR.mp4"> <video class="preview z-depth-1 rounded" width="100%" height="auto" autoplay="" muted="" loop="" playsinline="" preload="auto" loading="eager" poster="/assets/video/publication_preview/PhoneInVR.jpg" onerror="this.style.display='none'; document.getElementById('fallback-assets-video-publication-preview-phoneinvr-mp4').style.display='block';"> <source src="/assets/video/publication_preview/PhoneInVR.mp4" type="video/mp4"/> <source src="/assets/video/publication_preview/PhoneInVR.webm" type="video/webm"/> Your browser does not support the video tag. </video> <div class="video-play-overlay"> <div class="play-button-large"></div> </div> <div id="fallback-assets-video-publication-preview-phoneinvr-mp4" class="video-fallback" style="display:none;" data-video-path="/assets/video/publication_preview/PhoneInVR.mp4"> <img src="/assets/video/publication_preview/PhoneInVR.jpg" alt="Video preview image" class="preview z-depth-1 rounded"/> <div class="play-button-large"></div> </div> </div> </figure> <style>.video-container{position:relative;width:100%;cursor:pointer;overflow:hidden;border-radius:4px;transition:transform .3s ease,box-shadow .3s ease}.video-container:hover{transform:scale(1.01);box-shadow:0 4px 8px rgba(0,0,0,0.1)}.video-container video{display:block;max-width:100%}.video-play-overlay{position:absolute;top:0;left:0;width:100%;height:100%;background-color:rgba(0,0,0,0.1);opacity:0;transition:opacity .3s ease;display:flex;align-items:center;justify-content:center}.video-container:hover .video-play-overlay{opacity:1}.video-fallback{position:relative;width:100%;cursor:pointer}.video-fallback img{width:100%;height:auto;display:block;border-radius:4px}.play-button-large{width:80px;height:80px;background-color:rgba(0,0,0,0.6);border-radius:50%;display:flex;align-items:center;justify-content:center;transition:background-color .3s ease,transform .3s ease}.play-button-large:before{content:'';display:block;width:0;height:0;border-top:15px solid transparent;border-bottom:15px solid transparent;border-left:25px solid white;margin-left:5px}.video-container:hover .play-button-large,.video-fallback:hover .play-button-large{background-color:rgba(0,0,0,0.8);transform:scale(1.1)}</style> </div> <div id="PhoneInVR" class="col-sm-8 col-md-8 publication-content"> <div class="title"> PhoneInVR: An Evaluation of Spatial Anchoring and Interaction Techniques for Smartphone Usage in Virtual Reality </div> <div class="author"> <em>Fengyuan Zhu</em>,&nbsp;Mauricio Sousa ,&nbsp;Ludwig Sidenmark ,&nbsp;and&nbsp;Tovi Grossman </div> <div class="periodical"> <em>In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems</em> , Honolulu, HI, USA, 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/PhoneInVR.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.youtube.com/watch?v=pQN98TbhAKM" class="btn btn-sm z-depth-0" role="button">Video</a> </div> <div class="abstract hidden"> <p>When users wear a virtual reality (VR) headset, they lose access to their smartphone and accompanying apps. Past work has proposed smartphones as enhanced VR controllers, but little work has explored using existing smartphone apps and performing traditional smartphone interactions while in VR. In this paper, we consider three potential spatial anchorings for rendering smartphones in VR: On top of a tracked physical smartphone which the user holds (Phone-locked), on top of the users empty hand, as if holding a virtual smartphone (Hand-locked), or in a static position in front of the user (World-locked). We conducted a comparative study of target acquisition, swiping, and scrolling tasks across these anchorings using direct Touch or above-the-surface Pinch. Our findings indicate that physically holding a smartphone with Touch improves accuracy and speed for all tasks, and Pinch performed better with virtual smartphones. These findings provide a valuable foundation to enable smartphones in VR. </p> </div> </div> </div> </li> <li><div class="row publication-entry"> <div class="col-sm-4 col-md-4 abbr"> <figure> <div class="video-container" data-zoomable="" data-video-path="/assets/video/publication_preview/PinchLens.mp4"> <video class="preview z-depth-1 rounded" width="100%" height="auto" autoplay="" muted="" loop="" playsinline="" preload="auto" loading="eager" poster="/assets/video/publication_preview/PinchLens.jpg" onerror="this.style.display='none'; document.getElementById('fallback-assets-video-publication-preview-pinchlens-mp4').style.display='block';"> <source src="/assets/video/publication_preview/PinchLens.mp4" type="video/mp4"/> <source src="/assets/video/publication_preview/PinchLens.webm" type="video/webm"/> Your browser does not support the video tag. </video> <div class="video-play-overlay"> <div class="play-button-large"></div> </div> <div id="fallback-assets-video-publication-preview-pinchlens-mp4" class="video-fallback" style="display:none;" data-video-path="/assets/video/publication_preview/PinchLens.mp4"> <img src="/assets/video/publication_preview/PinchLens.jpg" alt="Video preview image" class="preview z-depth-1 rounded"/> <div class="play-button-large"></div> </div> </div> </figure> <style>.video-container{position:relative;width:100%;cursor:pointer;overflow:hidden;border-radius:4px;transition:transform .3s ease,box-shadow .3s ease}.video-container:hover{transform:scale(1.01);box-shadow:0 4px 8px rgba(0,0,0,0.1)}.video-container video{display:block;max-width:100%}.video-play-overlay{position:absolute;top:0;left:0;width:100%;height:100%;background-color:rgba(0,0,0,0.1);opacity:0;transition:opacity .3s ease;display:flex;align-items:center;justify-content:center}.video-container:hover .video-play-overlay{opacity:1}.video-fallback{position:relative;width:100%;cursor:pointer}.video-fallback img{width:100%;height:auto;display:block;border-radius:4px}.play-button-large{width:80px;height:80px;background-color:rgba(0,0,0,0.6);border-radius:50%;display:flex;align-items:center;justify-content:center;transition:background-color .3s ease,transform .3s ease}.play-button-large:before{content:'';display:block;width:0;height:0;border-top:15px solid transparent;border-bottom:15px solid transparent;border-left:25px solid white;margin-left:5px}.video-container:hover .play-button-large,.video-fallback:hover .play-button-large{background-color:rgba(0,0,0,0.8);transform:scale(1.1)}</style> </div> <div id="PinchLens" class="col-sm-8 col-md-8 publication-content"> <div class="title"> PinchLens: Applying Spatial Magnification and Adaptive Control-Display Gain for Precise Selection in Virtual Reality </div> <div class="author"> <em>Fengyuan Zhu</em>,&nbsp;Ludwig Sidenmark ,&nbsp;Mauricio Sousa ,&nbsp;and&nbsp;Tovi Grossman </div> <div class="periodical"> <em>In 2023 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</em> , Sydney, New South Wales, Australia, 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/PinchLens.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/MAlkiWVsMeQ?si=zPMXPQNwDKb0Yoc5" class="btn btn-sm z-depth-0" role="button">Video</a> </div> <div class="abstract hidden"> <p>We present PinchLens, a new free-hand target selection technique for acquiring small and dense targets in Virtual Reality. Traditional pinch-based selection does not allow people to precisely manipulate small and dense objects effectively due to tracking and perceptual inaccuracies. Our approach combines spatial magnification, an adaptive control-display gain, and visual feedback to improve selection accuracy. When a user starts the pinching selection process, a magnifying bubble expands the scale of nearby targets, an adaptive control-to-display ratio is applied to the user‘s hand for precision, and a cursor is displayed at the estimated pinch point for enhanced visual feedback. We performed a user study to compare our technique to traditional pinch selection and several variations to isolate the impact of each of the technique’s features. The results showed that PinchLens significantly outperformed traditional pinch selection, reducing error rates from 18.9% to 1.9%. Furthermore, we found that magnification was the dominant feature to produce this improvement, while the adaptive control-display gain and visual cursor of pinch were also helpful in several conditions.</p> </div> </div> </div> </li></ol> </div> <h2 id="how-to-add-video-previews-to-your-papers">How to Add Video Previews to Your Papers</h2> <p>Adding video previews to your publications is straightforward. In your BibTeX entries (typically in <code class="language-plaintext highlighter-rouge">_bibliography/papers.bib</code>), you need to add two key elements:</p> <ol> <li>Mark the paper as selected by adding <code class="language-plaintext highlighter-rouge">selected={true}</code></li> <li>Add a video preview by including <code class="language-plaintext highlighter-rouge">preview={YourPaperName.mp4}</code></li> </ol> <p>Here’s an example of a BibTeX entry with video preview:</p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@INPROCEEDINGS</span><span class="p">{</span><span class="nl">PaperKey</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Author, A. and Researcher, B.}</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Your Amazing Research Paper}</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{2025 Conference Proceedings}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2025}</span><span class="p">,</span>
  <span class="na">pages</span><span class="p">=</span><span class="s">{1-10}</span><span class="p">,</span>
  <span class="na">abstract</span><span class="p">=</span><span class="s">{Your paper abstract goes here...}</span><span class="p">,</span>
  <span class="na">selected</span><span class="p">=</span><span class="s">{true}</span><span class="p">,</span>
  <span class="na">preview</span><span class="p">=</span><span class="s">{YourPaperName.mp4}</span><span class="p">,</span>
  <span class="na">pdf</span><span class="p">=</span><span class="s">{YourPaper.pdf}</span><span class="p">,</span>
  <span class="na">video</span><span class="p">=</span><span class="s">{https://youtu.be/your-full-video}</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="video-requirements-and-tips">Video Requirements and Tips</h2> <p>For optimal results with video previews:</p> <ol> <li><strong>Format</strong>: Create MP4 files for best compatibility</li> <li><strong>Duration</strong>: Keep videos short (5-15 seconds) to quickly convey the key visual aspects</li> <li><strong>Size</strong>: Optimize file size to ensure fast loading</li> <li><strong>Content</strong>: Focus on the most visually interesting aspects of your research</li> <li><strong>No Audio</strong>: The videos play muted, so visual content is key</li> <li><strong>Fallback Image</strong>: The system automatically uses a JPG with the same name as fallback</li> </ol> <h2 id="file-organization">File Organization</h2> <p>Place your video preview files in the <code class="language-plaintext highlighter-rouge">/assets/video/publication_preview/</code> directory. The system will automatically look for them there.</p> <h2 id="benefits-of-video-previews">Benefits of Video Previews</h2> <p>Adding video previews to your selected papers offers several advantages:</p> <ul> <li><strong>Increased Engagement</strong>: Visitors are more likely to notice and explore papers with dynamic content</li> <li><strong>Better Understanding</strong>: Complex concepts can be quickly conveyed visually</li> <li><strong>Professional Appearance</strong>: Creates a modern, interactive showcase of your research</li> <li><strong>Differentiation</strong>: Stands out from traditional static publication lists</li> </ul> <p>By implementing video previews for your key publications, you can create a more engaging and informative academic website that effectively showcases your research contributions.</p>]]></content><author><name></name></author><category term="tutorials"/><category term="demo"/><category term="video"/><category term="publications"/><summary type="html"><![CDATA[How to add engaging video previews to your selected papers]]></summary></entry></feed>