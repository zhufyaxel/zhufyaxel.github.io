@inproceedings{BISHARE,
  author = {Zhu, Fengyuan and Grossman, Tovi},
  title = {BISHARE: Exploring Bidirectional Interactions Between Smartphones and Head-Mounted Augmented Reality},
  year = {2020},
  isbn = {9781450367080},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3313831.3376233},
  doi = {10.1145/3313831.3376233},
  abstract = {In pursuit of a future where HMD devices can be used in tandem with smartphones and other smart devices, we present BISHARE, a design space of cross-device interactions between smartphones and ARHMDs. Our design space is unique in that it is bidirectional in nature, as it examines how both the HMD can be used to enhance smartphone tasks, and how the smartphone can be used to enhance HMD tasks. We then present an interactive prototype that enables cross-device interactions across the proposed design space. A 12-participant user study demonstrates the promise of the design space and provides insights, observations, and guidance for the future.},
  booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages = {1–14},
  numpages = {14},
  keywords = {augmented reality, cross-device computing, mixed-reality computing, smartphones},
  location = {Honolulu, HI, USA},
  series = {CHI '20},
  dimensions={true},
  pdf={example_pdf.pdf},
  video={https://www.youtube.com/watch?v=hkL4cKUleNw},
  selected={true},
  preview={BISHARE.gif},
}

@inproceedings{PhoneInVR,
  author = {Zhu, Fengyuan and Sousa, Mauricio and Sidenmark, Ludwig and Grossman, Tovi},
  title = {PhoneInVR: An Evaluation of Spatial Anchoring and Interaction Techniques for Smartphone Usage in Virtual Reality},
  year = {2024},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3613904.3642582},
  doi = {10.1145/3613904.3642582},
  abstract = {When users wear a virtual reality (VR) headset, they lose access to their smartphone and accompanying apps.
Past work has proposed smartphones as enhanced VR controllers, but little work has explored using existing smartphone apps and performing traditional smartphone interactions while in VR. 
In this paper, we consider three potential spatial anchorings for rendering smartphones in VR: On top of a tracked physical smartphone which the user holds (Phone-locked), on top of the users empty hand, as if holding a virtual smartphone (Hand-locked), or in a static position in front of the user (World-locked). 
We conducted a comparative study of target acquisition, swiping, and scrolling tasks across these anchorings using direct Touch or above-the-surface Pinch. 
Our findings indicate that physically holding a smartphone with Touch improves accuracy and speed for all tasks, and Pinch performed better with virtual smartphones. These findings provide a valuable foundation to enable smartphones in VR. },
  booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
  keywords = {virtual reality, cross-device computing, mixed-reality computing, smartphones},
  location = {Honolulu, HI, USA},
  series = {CHI '24},
  pdf={example_pdf.pdf},
  dimensions={true},
  video={https://www.youtube.com/watch?v=pQN98TbhAKM},
  selected={true},
  preview={PhoneInVR.gif},
}

@INPROCEEDINGS{8115400,
  author={Li, Peiliang and Qin, Tong and Hu, Botao and Zhu, Fengyuan and Shen, Shaojie},
  booktitle={2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)}, 
  title={Monocular Visual-Inertial State Estimation for Mobile Augmented Reality}, 
  year={2017},
  volume={},
  number={},
  pages={11-21},
  keywords={Cameras;Feature extraction;Mobile handsets;Measurement;State estimation;Visualization;Robustness},
  doi={10.1109/ISMAR.2017.18},
  preview={vins.png},
}

@inproceedings{10.1145/3131785.3131795,
author = {He, Zhenyi and Zhu, Fengyuan and Perlin, Ken},
title = {PhyShare: Sharing Physical Interaction in Virtual Reality},
year = {2017},
isbn = {9781450354196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3131785.3131795},
doi = {10.1145/3131785.3131795},
abstract = {We present PhyShare, a new haptic user interface based on actuated robots. Virtual reality has recently been gaining wide adoption, and an effective haptic feedback in these scenarios can strongly support user's sensory in bridging virtual and physical world. Since participants do not directly observe these robotic proxies, we investigate the multiple mappings between physical robots and virtual proxies that can utilize the resources needed to provide a well rounded VR experience. PhyShare bots can act either as directly touchable objects or invisible carriers of physical objects, depending on different scenarios. They also support distributed collaboration, allowing remotely located VR collaborators to share the same physical feedback.},
booktitle = {Adjunct Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology},
pages = {17–19},
numpages = {3},
keywords = {virtual reality, robots, haptic user interfaces},
location = {Qu\'{e}bec City, QC, Canada},
series = {UIST '17 Adjunct}
}

@INPROCEEDINGS{TouchingTheDroid,
  author={Zhu, Fengyuan and Lyu, Zhuoyue and Sousa, Mauricio and Grossman, Tovi},
  booktitle={2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)}, 
  title={Touching The Droid: Understanding and Improving Touch Precision With Mobile Devices in Virtual Reality}, 
  year={2022},
  volume={},
  number={},
  abstract={Touch interaction with physical smartphones and tablets in Virtual Reality offers interesting opportunities for cross-device input. 
Unfortunately, any imprecision in the alignment of the visual representation of either the hand or device can impact the precision of touch and the realism of the experience. 
We first study a user`s ability to rely solely on preoperative feedback to perform touch interaction in VR, where no rendering of the hand is provided. 
Results indicate that touch in VR is possible without a visual representation of the hand, but accuracy is influenced by how the device is held and the distance traveled to the target. 
We then introduce a dynamic calibration algorithm to minimize the offset between the physical hand and its virtual representation. 
In a second study, we show that this algorithm can increase touch accuracy by 43\%, and minimize depth-based “screen penetration” or “floating touch” errors.},
  video={},
  preview={TouchTheDroid.gif},
  year={2022},
  location = {Singapore, Singapore},
  pdf={example_pdf.pdf},
  pages={807-816},
  keywords={Performance evaluation;Visualization;Heuristic algorithms;User interfaces;Rendering (computer graphics);Calibration;Reliability;Human-Centered Computing;Human computer interaction (HCI);Interaction Paradigms;Virtual Reality},
  doi={10.1109/ISMAR55827.2022.00099}
}

@INPROCEEDINGS{PinchLens,
  author={Zhu, Fengyuan and Sidenmark, Ludwig and Sousa, Mauricio and Grossman, Tovi},
  booktitle={2023 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)}, 
  title={PinchLens: Applying Spatial Magnification and Adaptive Control-Display Gain for Precise Selection in Virtual Reality}, 
  year={2023},
  volume={},
  number={},
  abstract ={We present PinchLens, a new free-hand target selection technique for acquiring small and dense targets in Virtual Reality. Traditional pinch-based selection does not allow people to precisely manipulate small and dense objects effectively due to tracking and perceptual inaccuracies. Our approach combines spatial magnification, an adaptive control-display gain, and visual feedback to improve selection accuracy. When a user starts the pinching selection process, a magnifying bubble expands the scale of nearby targets, an adaptive control-to-display ratio is applied to the user`s hand for precision, and a cursor is displayed at the estimated pinch point for enhanced visual feedback. We performed a user study to compare our technique to traditional pinch selection and several variations to isolate the impact of each of the technique’s features. The results showed that PinchLens significantly outperformed traditional pinch selection, reducing error rates from 18.9\% to 1.9\%.  Furthermore, we found that magnification was the dominant feature to produce this improvement, while the adaptive control-display gain and visual cursor of pinch were also helpful in several conditions.},
  pages={1221-1230},
  selected={true},
  location={Sydney, New South Wales, Australia},
  year={2023},
  pdf={example_pdf.pdf},
  video={https://youtu.be/MAlkiWVsMeQ?si=zPMXPQNwDKb0Yoc5},
  preview={PinchLens.gif},
  keywords={Visualization;Target tracking;Error analysis;Process control;Task analysis;Augmented reality;Human-centered computing;Human computer interaction (HCI);Interaction techniques},
  doi={10.1109/ISMAR59233.2023.00139}
}

@inproceedings{10.1145/2901790.2901800,
author = {Ma, Xiaojuan and Fang, Ke and Zhu, Fengyuan},
title = {From Breakage to Icebreaker: Inspiration for Designing Technological Support for Human-Human Interaction},
year = {2016},
isbn = {9781450340311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2901790.2901800},
doi = {10.1145/2901790.2901800},
abstract = {This paper explores why and how accidental breakage of technologies can promote humans to interact and ultimately lead to positive behavioral, emotional, and relational change. Through a set of research activities, including meta-synthesis of daily anecdotes, design workshops, and a case study, we gain insights into what may hinder or trigger human-human communication, and propose the conceptual and actionable process of Breakage-to-Icebreaker (B2I) design. Instead of intentionally breaking a technology, B2I design embeds mechanisms into existing products and services, creating opportunities for users to interpersonally interact online and/or offline while enjoying the original features and functionalities. Finally, we envision a broader and extended use of B2I thinking in everyday design research and practices.},
booktitle = {Proceedings of the 2016 ACM Conference on Designing Interactive Systems},
pages = {403–414},
pdf={example_pdf.pdf},
preview={dis16.png},
numpages = {12},
keywords = {icebreaker, human-human interaction, breakage},
location = {Brisbane, QLD, Australia},
series = {DIS '16}
}


